{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e85b903-68a9-46a4-ac51-585306540ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßë‚Äçüíª Tool: QA\n",
      "Input: What is LangGraph in LangChain?\n",
      "\n",
      "ü§ñ Output:\n",
      "In LangChain, LangGraph refers to a graph data structure that represents the relationships between different entities and pieces of information within a language model's output. It's essentially a way to visualize and interact with the knowledge graph generated by the model.\n",
      "\n",
      "Think of it like a map of concepts, entities, and their connections, which can be used for various tasks such as:\n",
      "\n",
      "1. **Knowledge graph construction**: LangGraph helps build a structured representation of the knowledge extracted from the language model.\n",
      "2. **Question answering**: It enables more accurate question-answering by allowing models to reason over the relationships between entities in the graph.\n",
      "3. **Text generation**: LangGraph can be used as a source of information for generating text, such as summaries or explanations.\n",
      "\n",
      "In summary, LangGraph is an essential component of LangChain that facilitates the creation and manipulation of knowledge graphs from language model outputs.\n",
      "\n",
      "üßë‚Äçüíª Tool: Summarizer\n",
      "Input: LangChain is a framework to build LLM apps using prompts, memory, tools, and agents.\n",
      "\n",
      "ü§ñ Output:\n",
      "The LangChain framework allows developers to create applications that utilize Large Language Models (LLMs) by incorporating four key components: prompts, memory, tools, and agents.\n",
      "\n",
      "üßë‚Äçüíª Tool: Web Search\n",
      "Input: Latest updates on GPT-4\n",
      "\n",
      "ü§ñ Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import Tool\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# =========================\n",
    "# Initialize Ollama LLM\n",
    "# =========================\n",
    "llm = OllamaLLM(model=\"llama3.1\", temperature=0)\n",
    "\n",
    "# =========================\n",
    "# Tool 1: QA Tool\n",
    "# =========================\n",
    "qa_prompt = PromptTemplate.from_template(\"Answer clearly: {question}\")\n",
    "qa_chain = qa_prompt | llm\n",
    "qa_tool = Tool(\n",
    "    name=\"QA Tool\",\n",
    "    func=lambda q: qa_chain.invoke({\"question\": q}),\n",
    "    description=\"Answer factual questions clearly\"\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Tool 2: Summarizer Tool\n",
    "# =========================\n",
    "sum_prompt = PromptTemplate.from_template(\"Summarize the following text:\\n{text}\")\n",
    "sum_chain = sum_prompt | llm\n",
    "sum_tool = Tool(\n",
    "    name=\"Summarizer Tool\",\n",
    "    func=lambda t: sum_chain.invoke({\"text\": t}),\n",
    "    description=\"Summarizes input text\"\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Tool 3: Web Search (Google scraping)\n",
    "# =========================\n",
    "def simple_search(query):\n",
    "    url = f\"https://www.google.com/search?q={query}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    results = []\n",
    "    for g in soup.find_all('div', class_='tF2Cxc')[:3]:\n",
    "        title = g.find('h3').text if g.find('h3') else \"\"\n",
    "        link = g.find('a')['href'] if g.find('a') else \"\"\n",
    "        results.append(f\"{title} - {link}\")\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"Web Search\",\n",
    "    func=simple_search,\n",
    "    description=\"Search Google without API key\"\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Manual multi-tool execution\n",
    "# =========================\n",
    "tools = {\n",
    "    \"QA\": qa_tool,\n",
    "    \"Summarizer\": sum_tool,\n",
    "    \"Web Search\": search_tool\n",
    "}\n",
    "\n",
    "queries = [\n",
    "    (\"QA\", \"What is LangGraph in LangChain?\"),\n",
    "    (\"Summarizer\", \"LangChain is a framework to build LLM apps using prompts, memory, tools, and agents.\"),\n",
    "    (\"Web Search\", \"Latest updates on GPT-4\")\n",
    "]\n",
    "\n",
    "for tool_name, user_input in queries:\n",
    "    print(f\"\\nüßë‚Äçüíª Tool: {tool_name}\")\n",
    "    print(f\"Input: {user_input}\")\n",
    "    output = tools[tool_name].run(user_input)\n",
    "    print(f\"\\nü§ñ Output:\\n{output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e077cc5d-9983-475c-a775-8d2cb3e14e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchainhope)",
   "language": "python",
   "name": "langchainhope"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
